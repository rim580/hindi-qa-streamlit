from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import re

text = ("‡§ö‡•ç‡§ö‡•Ä ‡§¶‡•ã‡§∏‡•ç‡§§‡•Ä ‡§µ‡§π‡•Ä ‡§π‡•à ‡§ú‡•ã ‡§Æ‡•Å‡§∂‡•ç‡§ï‡§ø‡§≤ ‡§µ‡§ï‡•ç‡§§ ‡§Æ‡•á‡§Ç ‡§∏‡§æ‡§• ‡§¶‡•á‡•§ ‡§Ø‡§π ‡§ï‡§π‡§æ‡§®‡•Ä ‡§¶‡•ã ‡§¶‡•ã‡§∏‡•ç‡§§‡•ã‡§Ç ‡§ï‡•Ä ‡§ó‡§π‡§∞‡•Ä ‡§¶‡•ã‡§∏‡•ç‡§§‡•Ä ‡§ï‡•Ä ‡§π‡•à‡•§ ‡§∞‡§æ‡§π‡•Å‡§≤ ‡§î‡§∞ ‡§∏‡•ã‡§π‡§® ‡§è‡§ï ‡§π‡•Ä ‡§ó‡§æ‡§Å‡§µ ‡§Æ‡•á‡§Ç ‡§∞‡§π‡§§‡•á ‡§•‡•á‡•§ ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§¨‡§ö‡§™‡§® ‡§∏‡•á ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§•‡•á‡•§ ‡§µ‡•ã ‡§∏‡§æ‡§• ‡§Æ‡•á‡§Ç ‡§∏‡•ç‡§ï‡•Ç‡§≤ ‡§ú‡§æ‡§§‡•á, ‡§∏‡§æ‡§• ‡§Æ‡•á‡§Ç ‡§ñ‡•á‡§≤‡§§‡•á ‡§î‡§∞ ‡§Ö‡§™‡§®‡•Ä ‡§π‡§∞ ‡§¨‡§æ‡§§ ‡§è‡§ï-‡§¶‡•Ç‡§∏‡§∞‡•á ‡§∏‡•á ‡§¨‡§æ‡§Å‡§ü‡§§‡•á ‡§•‡•á‡•§ ‡§∞‡§æ‡§π‡•Å‡§≤ ‡§∂‡§æ‡§Ç‡§§ ‡§∏‡•ç‡§µ‡§≠‡§æ‡§µ ‡§ï‡§æ ‡§•‡§æ, ‡§ú‡§¨‡§ï‡§ø ‡§∏‡•ã‡§π‡§® ‡§π‡§Å‡§∏‡§Æ‡•Å‡§ñ ‡§î‡§∞ ‡§π‡§ø‡§Æ‡•ç‡§Æ‡§§‡•Ä ‡§•‡§æ‡•§ ‡§è‡§ï ‡§¶‡§ø‡§® ‡§ó‡§∞‡•ç‡§Æ‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•Ä ‡§õ‡•Å‡§ü‡•ç‡§ü‡§ø‡§Ø‡§æ‡§Å ‡§•‡•Ä‡§Ç‡•§ ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§ú‡§Ç‡§ó‡§≤ ‡§Æ‡•á‡§Ç ‡§ñ‡•á‡§≤‡§®‡•á ‡§ó‡§è‡•§ ‡§µ‡§π‡§æ‡§Å ‡§è‡§ï ‡§™‡•Å‡§∞‡§æ‡§®‡§æ ‡§ï‡•Å‡§Ü‡§Å ‡§•‡§æ, ‡§ú‡•ã ‡§∏‡•Ç‡§ñ ‡§ö‡•Å‡§ï‡§æ ‡§•‡§æ‡•§ ‡§∞‡§æ‡§π‡•Å‡§≤ ‡§ñ‡•á‡§≤‡§§‡•á-‡§ñ‡•á‡§≤‡§§‡•á ‡§â‡§∏ ‡§ï‡•Å‡§è‡§Å ‡§ï‡•á ‡§™‡§æ‡§∏ ‡§ó‡§Ø‡§æ ‡§î‡§∞ ‡§Ö‡§ö‡§æ‡§®‡§ï ‡§â‡§∏‡§ï‡§æ ‡§™‡•à‡§∞ ‡§´‡§ø‡§∏‡§≤ ‡§ó‡§Ø‡§æ‡•§ ‡§µ‡•ã ‡§ï‡•Å‡§è‡§Å ‡§Æ‡•á‡§Ç ‡§ó‡§ø‡§∞ ‡§™‡§°‡§º‡§æ‡•§‡§∞‡§æ‡§π‡•Å‡§≤ ‡§®‡•á ‡§ú‡•ã‡§∞ ‡§∏‡•á ‡§ö‡§ø‡§≤‡•ç‡§≤‡§æ‡§Ø‡§æ, ‚Äú‡§∏‡•ã‡§π‡§®, ‡§Æ‡•Å‡§ù‡•á ‡§¨‡§ö‡§æ‡§ì! ‡§Æ‡•à‡§Ç ‡§Ø‡§π‡§æ‡§Å ‡§∏‡•á ‡§®‡§ø‡§ï‡§≤ ‡§®‡§π‡•Ä‡§Ç ‡§∏‡§ï‡§§‡§æ‡•§‚Äù ‡§∏‡•ã‡§π‡§® ‡§ò‡§¨‡§∞‡§æ ‡§ó‡§Ø‡§æ, ‡§≤‡•á‡§ï‡§ø‡§® ‡§â‡§∏‡§®‡•á ‡§π‡§ø‡§Æ‡•ç‡§Æ‡§§ ‡§®‡§π‡•Ä‡§Ç ‡§π‡§æ‡§∞‡•Ä‡•§ ‡§â‡§∏‡§®‡•á ‡§Ü‡§∏‡§™‡§æ‡§∏ ‡§¶‡•á‡§ñ‡§æ ‡§§‡•ã ‡§â‡§∏‡•á ‡§è‡§ï ‡§™‡•Å‡§∞‡§æ‡§®‡•Ä ‡§∞‡§∏‡•ç‡§∏‡•Ä ‡§¶‡§ø‡§ñ‡•Ä, ‡§ú‡•ã ‡§™‡§æ‡§∏ ‡§ï‡•á ‡§™‡•á‡§°‡§º ‡§∏‡•á ‡§¨‡§Å‡§ß‡•Ä ‡§•‡•Ä‡•§ ‡§µ‡•ã ‡§¶‡•å‡§°‡§º‡§ï‡§∞ ‡§∞‡§∏‡•ç‡§∏‡•Ä ‡§≤‡•á ‡§Ü‡§Ø‡§æ ‡§î‡§∞ ‡§â‡§∏‡•á ‡§ï‡•Å‡§è‡§Å ‡§Æ‡•á‡§Ç ‡§°‡§æ‡§≤‡§æ‡•§ ‡§â‡§∏‡§®‡•á ‡§ï‡§π‡§æ, ‚Äú‡§∞‡§æ‡§π‡•Å‡§≤, ‡§á‡§∏‡•á ‡§™‡§ï‡§°‡§º‡•ã ‡§î‡§∞ ‡§ä‡§™‡§∞ ‡§ö‡§¢‡§º‡§®‡•á ‡§ï‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•ã‡•§‚Äù ‡§∞‡§æ‡§π‡•Å‡§≤ ‡§®‡•á ‡§∞‡§∏‡•ç‡§∏‡•Ä ‡§™‡§ï‡§°‡§º‡•Ä ‡§î‡§∞ ‡§∏‡•ã‡§π‡§® ‡§®‡•á ‡§ä‡§™‡§∞ ‡§∏‡•á ‡§™‡•Ç‡§∞‡•Ä ‡§§‡§æ‡§ï‡§§ ‡§≤‡§ó‡§æ‡§ï‡§∞ ‡§â‡§∏‡•á ‡§ñ‡•Ä‡§Ç‡§ö‡§æ‡•§ ‡§ï‡§à ‡§ï‡•ã‡§∂‡§ø‡§∂‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§∞‡§æ‡§π‡•Å‡§≤ ‡§¨‡§æ‡§π‡§∞ ‡§Ü ‡§ó‡§Ø‡§æ‡•§ ‡§â‡§∏‡§ï‡•Ä ‡§∏‡§æ‡§Å‡§∏‡•á‡§Ç ‡§§‡•á‡§ú‡§º ‡§ö‡§≤ ‡§∞‡§π‡•Ä ‡§•‡•Ä‡§Ç‡•§ ‡§â‡§∏‡§®‡•á ‡§∏‡•ã‡§π‡§® ‡§ï‡•ã ‡§ó‡§≤‡•á ‡§≤‡§ó‡§æ‡§Ø‡§æ ‡§î‡§∞ ‡§ï‡§π‡§æ, ‚Äú‡§Ö‡§ó‡§∞ ‡§§‡•Ç ‡§® ‡§π‡•ã‡§§‡§æ ‡§§‡•ã ‡§Æ‡•à‡§Ç ‡§Ü‡§ú ‡§Æ‡§∞ ‡§ú‡§æ‡§§‡§æ‡•§ ‡§§‡•Ç ‡§Æ‡•á‡§∞‡§æ ‡§∏‡§ö‡•ç‡§ö‡§æ ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§π‡•à‡•§‚Äù ‡§∏‡•ã‡§π‡§® ‡§π‡§Å‡§∏‡§æ ‡§î‡§∞ ‡§¨‡•ã‡§≤‡§æ, ‚Äú‡§¶‡•ã‡§∏‡•ç‡§§‡•Ä ‡§Æ‡•á‡§Ç ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶ ‡§®‡§π‡•Ä‡§Ç ‡§¨‡•ã‡§≤‡§§‡•á‡•§ ‡§§‡•Ç ‡§Æ‡•á‡§∞‡§æ ‡§≠‡§æ‡§à ‡§π‡•à‡•§‚Äù‡§â‡§∏ ‡§ò‡§ü‡§®‡§æ ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§â‡§®‡§ï‡•Ä ‡§¶‡•ã‡§∏‡•ç‡§§‡•Ä ‡§î‡§∞ ‡§Æ‡§ú‡§º‡§¨‡•Ç‡§§ ‡§π‡•ã ‡§ó‡§à‡•§ ‡§∏‡§æ‡§≤‡•ã‡§Ç ‡§¨‡§æ‡§¶ ‡§∞‡§æ‡§π‡•Å‡§≤ ‡§è‡§ï ‡§¨‡§°‡§º‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞‡•Ä ‡§¨‡§®‡§æ‡•§ ‡§â‡§∏‡§®‡•á ‡§∏‡•ã‡§π‡§® ‡§ï‡•ã ‡§Ö‡§™‡§®‡•á ‡§µ‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§™‡§æ‡§∞‡•ç‡§ü‡§®‡§∞ ‡§¨‡§®‡§æ‡§Ø‡§æ‡•§ ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§®‡•á ‡§Æ‡§ø‡§≤‡§ï‡§∞ ‡§¨‡§π‡•Å‡§§ ‡§®‡§æ‡§Æ ‡§ï‡§Æ‡§æ‡§Ø‡§æ‡•§ ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§ó‡§æ‡§Å‡§µ ‡§Æ‡•á‡§Ç ‡§Æ‡•á‡§≤‡§æ ‡§≤‡§ó‡§æ, ‡§§‡•ã ‡§∞‡§æ‡§π‡•Å‡§≤ ‡§®‡•á ‡§∏‡•ã‡§π‡§® ‡§ï‡•ã ‡§∏‡•ç‡§ü‡•á‡§ú ‡§™‡§∞ ‡§¨‡•Å‡§≤‡§æ‡§Ø‡§æ ‡§î‡§∞ ‡§ï‡§π‡§æ, ‚Äú‡§Ø‡•á ‡§Æ‡•á‡§∞‡§æ ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§π‡•à, ‡§ú‡§ø‡§∏‡§®‡•á ‡§Æ‡•á‡§∞‡•Ä ‡§ú‡§æ‡§® ‡§¨‡§ö‡§æ‡§à‡•§ ‡§Ü‡§ú ‡§ú‡•ã ‡§ï‡•Å‡§õ ‡§≠‡•Ä ‡§π‡•Ç‡§Å, ‡§â‡§∏‡§Æ‡•á‡§Ç ‡§á‡§∏‡§ï‡§æ ‡§¨‡§π‡•Å‡§§ ‡§¨‡§°‡§º‡§æ ‡§π‡§æ‡§• ‡§π‡•à‡•§‚Äù ‡§∏‡•ã‡§π‡§® ‡§®‡•á ‡§≠‡•Ä ‡§π‡§Å‡§∏‡§ï‡§∞ ‡§ï‡§π‡§æ, ‚Äú‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§¶‡•ã‡§∏‡•ç‡§§‡•Ä ‡§π‡§Æ‡•á‡§∂‡§æ ‡§ê‡§∏‡•Ä ‡§π‡•Ä ‡§∞‡§π‡•á‡§ó‡•Ä‡•§‚Äù ‡§ó‡§æ‡§Å‡§µ ‡§µ‡§æ‡§≤‡•á ‡§â‡§®‡§ï‡•Ä ‡§¶‡•ã‡§∏‡•ç‡§§‡•Ä ‡§ï‡•Ä ‡§§‡§æ‡§∞‡•Ä‡§´ ‡§ï‡§∞‡§§‡•á ‡§®‡§π‡•Ä‡§Ç ‡§•‡§ï‡§§‡•á ‡§•‡•á‡•§")
class HindiQASystem:
    def __init__(self,text,chunk_size=3):
      self.original_text = text
      self.chunk_size = chunk_size

      self.chunks = []           # Will store text chunks
      self.vectorizer = None     # Will store TF-IDF vectorizer
      self.tfidf_matrix = None

    
      self._process_text()

      
      self._create_index()

      print("Q&A System is ready!\n")

  
    def _process_text(self):
       #split text on barakhadi
      sentences = re.split(r'[‡•§\?!]+', self.original_text)
       #remove spaces and empty strings     
      sentences = [s.strip() for s in sentences if s.strip()] 
      print(f"   Found {len(sentences)} sentences in the text")

       #creating chunks
      for i in range(0, len(sentences), self.chunk_size):

          chunk_sentences = sentences[i:i + self.chunk_size]
          chunk = ' '.join(chunk_sentences)
          if chunk:
              self.chunks.append(chunk)  
      print(f"   Created {len(self.chunks)} chunks")

    def _create_index(self):
      self.vectorizer = TfidfVectorizer(
              ngram_range=(1, 2),  # Use single words and word pairs
              min_df=1,            # Minimum document frequency
              max_df=0.8,          # Maximum document frequency (ignore very common words)
              sublinear_tf=True    # Use logarithmic term frequency
          )
      self.tfidf_matrix = self.vectorizer.fit_transform(self.chunks)
          
      print(f"   Created vectors with {self.tfidf_matrix.shape[1]} unique features")
      print(f"   Matrix shape: {self.tfidf_matrix.shape}")

    def search(self,query,top_k=3):
      query_vector = self.vectorizer.transform([query])
          
          # Calculate cosine similarity between query and all chunks
          # Cosine similarity ranges from 0 (completely different) to 1 (identical)
      similarities = cosine_similarity(query_vector, self.tfidf_matrix)[0]
          
          # Find the top_k most similar chunks
          # argsort gives indices, [-top_k:] takes last k, [::-1] reverses order
      top_indices = np.argsort(similarities)[-top_k:][::-1]
          
          # Collect results
      results = []
      for idx in top_indices:
              if similarities[idx] > 0:  # Only include if there's some similarity
                  results.append((
                      self.chunks[idx],      # The chunk text
                      similarities[idx],      # Similarity score
                      idx                     # Chunk index
                  ))
          
      return results
      
    # ------------------------------------------------------------------------
    # STEP 6: Answer Question Function
    # Main function users will call
    # ------------------------------------------------------------------------
    
    def answer_question(self, question, top_k=3, show_scores=False):
        """
        Answer a question by retrieving relevant text chunks
        
        Parameters:
        -----------
        question : str
            The question in Hindi
        top_k : int
            Number of chunks to retrieve
        show_scores : bool
            Whether to show similarity scores
            
        Returns:
        --------
        str : Formatted answer with relevant chunks
        """
        # Search for relevant chunks
        results = self.search(question, top_k)
        
        # If no results found
        if not results:
            return "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§Æ‡•Å‡§ù‡•á ‡§á‡§∏ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§ï‡§æ ‡§â‡§§‡•ç‡§§‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡§æ‡•§"
        
        # Format the answer
        answer = f"‡§™‡•ç‡§∞‡§∂‡•ç‡§®: {question}\n\n"
        answer += "‡§â‡§§‡•ç‡§§‡§∞ (‡§∏‡§Ç‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä):\n"
        answer += "=" * 60 + "\n\n"
        
        for i, (chunk, score, idx) in enumerate(results, 1):
            answer += f"{i}. {chunk}\n"
            if show_scores:
                answer += f"   üìä ‡§∏‡§Æ‡§æ‡§®‡§§‡§æ ‡§∏‡•ç‡§ï‡•ã‡§∞: {score:.3f}\n"
            answer += "\n"
        
        return answer
    
    # ------------------------------------------------------------------------
    # STEP 7: Display System Info (Optional but useful)
    # ------------------------------------------------------------------------
    
    def get_system_info(self):
        """
        Display information about the Q&A system
        """
        info = "=" * 60 + "\n"
        info += "üìö Hindi Q&A System Information\n"
        info += "=" * 60 + "\n"
        info += f"Total text length: {len(self.original_text)} characters\n"
        info += f"Chunk size: {self.chunk_size} sentences\n"
        info += f"Number of chunks: {len(self.chunks)}\n"
        info += f"Vocabulary size: {len(self.vectorizer.vocabulary_)} unique words\n"
        info += "=" * 60
        return info


# ============================================================================
# STEP 8: Example Usage
# ============================================================================

if __name__ == "__main__":
    print("\n" + "="*70)
    print("‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§™‡•ç‡§∞‡§∂‡•ç‡§®-‡§â‡§§‡•ç‡§§‡§∞ ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä - Complete Build")
    print("="*70 + "\n")
    
   
    
    # Create the Q&A system
    qa_system = HindiQASystem(text, chunk_size=2)
    
    # Display system information
    print(qa_system.get_system_info())
    
    # Ask some questions
    print("\n" + "="*70)
    print("‡§™‡•ç‡§∞‡§∂‡•ç‡§®‡•ã‡§Ç ‡§ï‡•á ‡§â‡§§‡•ç‡§§‡§∞:")
    print("="*70 + "\n")
    
    questions = ["‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•á ‡§¶‡•ã ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§™‡§æ‡§§‡•ç‡§∞ ‡§ï‡•å‡§® ‡§π‡•à‡§Ç?,‡§∞‡§æ‡§π‡•Å‡§≤ ‡§î‡§∞ ‡§∏‡•ã‡§π‡§® ‡§ï‡§π‡§æ‡§Å ‡§∞‡§π‡§§‡•á ‡§•‡•á?,‡§∞‡§æ‡§π‡•Å‡§≤ ‡§ï‡§æ ‡§∏‡•ç‡§µ‡§≠‡§æ‡§µ ‡§ï‡•à‡§∏‡§æ ‡§•‡§æ?"]
    
    for question in questions:
        answer = qa_system.answer_question(question, top_k=2, show_scores=True)
        print(answer)
        print("-"*70 + "\n")
    

